
#  운영체제와 정보기술의 원리

운영체제란?
- 컴퓨터를 지배하는 가장 체계적인 소프트웨어
- 컴퓨터 하드웨어 바로 윗단에 설치된다.
- 사용자 및 다른 모든 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층이다.
- 컴퓨터의 전원을 키면 운영체제가 동시에 실행되고 운영체제도 소프프트웨어이므로 동시에 메모리에 올라간다. 이때 메모리에 올라가는 꼭 필요한 부분은 커널(kernel)이라고 한다. 커널은 운영체제의 핵심적인 부분이며 나머지 부분은 필요할 때 메모리로 올려서 사용한다.

운영체제의 기능

- 기본적인 역할
	- 하드웨어를 위한 역할
		- 사용자가 직접 다루기 힘든 각종 하드웨어를 운영체제가 관리한다.
		- 시스템 내의 자원을 효율적으로 관리한다.
		- 운영체제는 자원 관리자(resource manager)라고 부르기도 한다.
		- 이 때 자원은 CPU, 메모리, 하드디스크, 각종 소프트웨어를 의미한다.
		- 운영체제는 이러한 자원을 효율적으로 관리하여 가장 좋은 성능을 내도록 한다.
		- 어떻게 효율적으로 좋은 성능을 낼 수 있을까?
		- 어떻게 자원을 형평성 있게 분배할 수 있을까?
	- 사용자를 위한 역할
		- 사용자에게는 편리한 인터페이스를 제공한다.
		- 시스템을 편리하게 사용할 수 있는 환경을 제공한다.

운영체제 분류

- single tasking
	- 한번에 하나의 프로그램만 실행 가능
- multitasking
	- 여러 프로그램이 CPU와 메모리를 공유해서 작업한다.
- time sharing system (시분할 시스템)
	- 여러 프로그램들이 CPU에서 번갈아 실행되면 사용자 입장에서 동시에 실행되는 것처럼 보인다.
	- CPU의 작업시간을 여러 프로그램이 조금씩 나누어 사용한다.
- multi-programming system
	- 여러 프로그램을 동시에 메모리에 올려놓고 처리하는 시스템
- interactive system (대화형 시스템)
	- 사용자는 입력 결과를 실시간으로 확인할 수 있다.
- multi-processor system (다중처리기 시스템)
	- 하나의 컴퓨터에 여러 CPU가 설치되어 동작한다.
	- 여러 프로그램이 동시에 실행되어 속도가 빠르지만 여러 CPU를 관리하기 위해 복잡한 매커니즘을 필요로 한다.
- 다중 사용자에 대한 동시 지원 여부
	- 단일 사용자용 운영체제
		- dos, window
	- 다중 사용자용 운영체제
		- 웹 서버, 이메일 서버
- 작업 처리 방식
	- batch 방식
		- 요청된 작업을 일정량씩 모아서 한번에 처리하는 방식
		- 사용자 입장에서 응답시간이 길어진다.
	- 시분할 방식
		- 여러 작업을 수행할 때 컴퓨터의 처리 능력을 일정한 시간 단위로 분할해 사용하는 방식
		- 사용자 입장에서 응답시간이 짧다.
	- 실시간 방식
		- 실시간 운영체제는 정해진 시간 안에 어떠한 일이 반드시 처리됨을 보장해야하는 시스템에서 사용됨.
		- hard realtime system
			- 주어진 시간을 지키지 못할 경우 매우 위험한 결과를 초래할 가능성이 있는 시스템
			- 로켓, 원자로 제어시스템
		- soft realtime system
			- 데이터가 정해진 시간 단위로 전달되어야 올바른 기능을 수행할 수 있는 시스템
			- 멀티미디어 스트리밍 시스템

운영체제의 자원 관리 기능
- 하드웨어 자원
	- CPU
		- 어떤 프로그램에 CPU를 할당할 것인가? (CPU 스케줄링)
		- CPU를 효율적으로 사용하면서도 특정 프로세스가 불이익을 당하지 않도록 하는 것이 목표이다.
		- 선입선출(First Come, First Served)
		- 라운드 로빈 (Round Robin)
		- CPU를 한번 할당받아 사용할 수 있는 시간을 일정하게 고정된 시간으로 제한하고 작업을 다 처리하지 못하더라도 제한 시간이 지나면 CPU 대기열의 맨 뒤로 가서 대기한다.
		- 우선순위(Priority)
	- Memory
		- 한정된 메모리를 어떻게 나누어 사용할 것인가?
		- 메모리는 CPU가 직접 접근할 수 있는 컴퓨터 내부의 기억장치이다.
		- 프로그램이 CPU에서 실행되려면 해당 부분이 메모리에 올라가 있어야 한다.
		- 운영체제는 메모리의 어느 부분이 어떤 프로그램에 의해 사용되고 있는지를 파악하여 유지하고 관리한다. address(주소)를 통해 관리된다.
		- 운영체제는 프로그램에 메모리가 필요할 때 할당하고, 더 이상 필요하지 않을 때 회수한다.
		- 운영체제는 각 프로세스가 자신의 메모리 영역에만 접근할 수 있게 관리하는 역할도 수행한다.
		- 고정 분할(fixed partition)
		- 가변 분할(variable partition)
		- 가상 메모리(virtual memory)
	- 보조기억장치
		- 디스크에 파일을 어떻게 보관할 것인가?
	- 입출력 장치
		- 각기 다른 입출력 장치와 컴퓨터 간에 어떻게 정보를 주고 받을 것인가?
		- interrupt 매커니즘을 통해 관리된다.
		- 주변 장치들은 해당 장치에서 일어나는 업무를 관리하기 위해 일종의 작은 CPU인 controller(제어기)를 가지고 있다.
		- 사용자로부터 입력이 들어오면 키보드 컨트롤러가 interrupt 신호를 CPU에게 신호를 발생시킨다.
		- CPU는 인터럽트 신호가 발생하면 수행하던 작업을 임시 저장 후 인터럽트 신호를 발생시킨 작업을 수행한다.
		- 운영체제는 인터럽트의 종류마다 서로 다른 인터럽트 처리 루틴은 운영체제 커널 내에 존재하는 코드로 가지고 있다.
		- 인터럽트가 발생하면 운영체제는 해당하는 인터럽트 처리루틴을 찾아서 정의된 코드에 따라 일을 수행하게 된다.
- 소프트웨어 자원

##  컴퓨터 시스템의 동작 원리

- 컴퓨터 시스템의 구조
	- 내부장치
		- 컴퓨터는 외부장치에서 내부장치로 데이터를 읽어와 각종 연산을 수행한 후 그 결과를 외부장치로 다시 내보내는 방식으로 업무를 처리한다.
		- CPU
		- 메모리
		- 외부장치
		- 입출력 장치
			- 입출력 장치마다 이를 제어하기 위해 설치된 장치 컨트롤러는 장치로 부터 들어오고 나가는 데이터를 임시로 저장하기 위한 작은 메모리인 로컬 버퍼local buffer 를 가지고 있다.
			- 로컬 버퍼로 다 읽어 오면 컨트롤러가 인터럽트 신호를 발생시켜 CPU에 보고한다.
			- CPU는 작업 도중 인터럽트 라인에 신호가 들어오면 하던 일을 멈추고 인터럽트와 관련된 일을 먼저 처리한다. 명령 하나를 수행할 때마다 인터럽트가 발생했는지 확인한다.
			- CPU 연산과 I/O 연산
			- CPU 연산과 입출력 장치들의 I/O 연산은 동시에 수행가능하다.
			- 기본적으로 CPU는 매 시점 메모리에서 명령(instruction)을 하나씩 읽어와서 수행한다.
	- 인터럽트
		- 하드웨어 인터럽트
			- 컨트롤러 등 하드웨어 장치가 CPU의 인터럽트 라인을 세팅한다. 인터럽트 라인은 인터럽트 신호를 받는다.
		- 소트웨어 인터럽트
			- trap 이라고 불린다.
			- 소프트웨어가 CPU의 인터럽트 라인을 세팅한다.
		- 예외 사항(exception)
			- 비정상적인 작업 시도하거나 자신의 메모리 영역 바깥에 접근을 시도하는 권한없는 작업을 시도할 때 이에 대한 처리를 위해 발생시키는 인터럽트를 말한다.
	- 시스템 콜(system call)
		- 사용자 프로그램이 운영체제 내부에 정의된 코드를 실행하고 싶을 때 운영체제에 서비스를 요청하는 방법이라고 볼 수 있다.
		- 사용자 프로그램이 운영체제 커널에 있는 코드를 실행하고자 할 때 인터럽트 라인 세팅을 통해 CPU 제어권을 운영체제로 넘겨 실행한다.
	- 인터럽트 핸들링 과정
		- 프로그램이 실행되고 있을 때 인터럽트가 발생하면 현재 프로그램의 상태를 저장한다.
		- 실행중인 명령의 메모리 주소값
		- 인터럽트가 발생해 새로운 명령을 실행하면 CPU 내부 임시 기억장치인 register의 기존 데이터가 지워지므로 CPU 내의 상태정보 등
		- 운영체제는 현재 시스템 내에서 실행되는 프로그램을 관리하기 위해 프로세스 제어 블록(Process Control Block, PCB) 이라는 자료구조를 둔다.
		- PCB는 각각의 프로그램마다 하나씩 존재하며 해당 프로그램의 어느 부분이 실행중이 었는지를 저장하고 있다. (프로그램이 실행중이던 코드의 메모리 주소와 레지스터값, 하드웨어 상태 등)
		- CPU의 제어권을 인터럽트 처리 루틴으로 넘겨 인터럽트 처리를 한다.
		- 처리가 끝나면 저장된 상태를 PCB로부터 CPU 상에 복원해 인터럽트 당하기 직전의 위치부터 실행이 이어지게 된다.
		- 오늘날 운영체제는 인터럽트가 발생할 때에만 실행된다.
		- 운영체제는 인터럽트가 발생했을 때에만 잠깐 CPU의 제어권을 획득할 수 있다.
		- 사용자 프로그램은 인터럽트가 발생하지 않으면 원하는 만큼 CPU를 계속 점유하고 있게 된다.

###  입출력 구조

- 입출력(I/O)란 컴퓨터 시스템이 컴퓨터 외부의 입출력 장치들과 데이터를 주고받는 것을 말한다.
	- 방식
	- 동기식 입출력
		- 입출력 작업이 완료된 후에 프로그램이 후속 작업을 수행할 수 있는 방식
		- CPU는 입출력 연산이 끝날 때까지 인터럽트를 기다리면 자원을 낭비하게 된다.
		- 이러한 낭비를 막기 위해 입출력 작업 수행 중인 경우 CPU를 다른 프로그램에게 이양해 계속 일할 수 있도록 관리한다.
		- 입출력 중인 프로그램을 Blocked State로 전환하여 관리한다.
		- 동기식 입출력 요청의 동기화를 위해 장치별로 queue를 두어 요청한 순서대로 처리한다.
		- 입출력 연산이 끝나면 인터럽트가 CPU에게 신호를 주고 운영체제 커널은 인터럽트 처리루틴으로 가서 입출력 연산을 끝낸 프로그램이 CPU를 할당받을 수 있도록 프로그램의 blocked state 를 해제시킨다.
		- 일반적으로 운영체제는 보통 동기식 입출력을 사용하여 동기성을 보장하게 한다.
	- 비동기식 입출력
		- 입출력 연산을 요청한 후에 대기하지 않고 CPU 제어권을 입출력 연산을 호출한 그 프로그램에게 곧바로 다시 부여한다.
		- 입출력 연산 작업과 관계없는 다른 작업을 병행하여 수행할 수 있다.
		- 입출력 작업이 끝나면 끝난 시점부터 읽어온 데이터를 필요로 하는 명령을 수행할 수 있게된다.

###  DMA(Direct Memory Access)

- 원칙적으로 메모리는 CPU에 의해서만 접근할 수 있는 장치이다. CPU 외의 장치가 메모리의 데이터에 접근하기 위해서는 CPU에게 인터럽트를 발생시켜 CPU가 이를 대행하는 식으로만 가능하다.
- 하지만 모든 메모리 접근 연산이 CPU에 의해서만 이루어질 경우 입출력 장치가 메모리 접근을 원할 때마다 인터럽트에 의해 CPU의 업무가 방해를 받게되어 효율성이 감소하기 때문에 CPU 이외의 메모리 접근 가능 장치인 DMA를 두는 경우가 많다.
- DMA를 사용하면 CPU에 발생하는 인터럽트를 줄일 수 있다.
- DMA를 사용하게 되면 로컬 버퍼에서 메모리로 읽어오는 작업을 CPU 대신 수행한다.
- DMA는 byte 단위가 아니라 block이라는 큰 단위로 정보를 메모리로 읽어온 후에 CPU에게 인터럽트를 발생시킨다.

###  저장 장치

- 구조
	- 주 기억 장치
		- 메모리
			- 전원이 나가면 저장된 내용이 사라지는 휘발성 RAM
	- 보조 기억 장치
		- 전원이 나가도 저장된 내용을 기억할 수 있는 비휘발성
		- 파일 시스템 용도로 사용
		- 메모리의 연장 공간인 swap area (스왑영역) 용으로 사용
		- 운영체제가 프로그램 수행에 당장 필요한 부분만 메모리에 올려놓고 그렇지 않은 부분은 디스크의 swap area에 내려놓고 사용한다.

- 계층 구조
	- 속도가 빠른 저장장치는 가격이 높아서 적은 용량으로 사용하게 된다. 속도가 느린 저장 장치는 가격이 싸서 많은 용량으로 사용하게 된다.
	- 당장 필요한 정보는 빠른 저장장치에 넣어두어 빠르게 사용할 수 있게 하고 그렇지 않은 정보는 느린 저장장치에 저장하여 사용한다.
	- 빠른 저장장치에 빈번하게 사용되는 정보를 저장하면 필요한 정보를 빠른 저장장치에서 곧바로 찾아서 사용할 수 있기 때문에 전체적인 성능이 향상된다.

###  하드웨어의 보안

- 운영체제는 하드웨어의 보안을 유지하기 위해 커널모드(kernel mode, system mode)와 사용자 모드(user mode) 2가지 모드를 지원한다.
- 중요한 정보에 접근할 수 있는 연산은 커널모드에서만 수행한다. 일반적인 연산만 사용자 모드에서 사용자 프로그램이 수행할 수 있게 허용한다.
- 커널 모드
	- 운영체제가 CPU의 제어권을 가지고 운영체제 코드를 실행.
	- 제한 없이 모든 명령 실행 가능
	- 인터럽트가 발생할 때 CPU의 제어권이 다시 운영체제로 넘어오면 mode bit는 자동으로 0이 세팅된다.
	- 모든 입출력 명령은 커널모드에서만 실행 가능하다. 사용자모드에서 입출력이 필요할 때 운영체제에 대신 요청해야 수행가능하다.(system call)

- 사용자모드
	- 사용자 프로그램은 제한적인 명령만 수행 가능
	- 사용자 프로그램이 CPU를 가지고 있는 동안에 운영체제가 사용자 프로그램을 감시하기 위해 컴퓨터 시스템 CPU 내부에 mode bit를 두고 있다. mode bit 가 0으로 세팅되어 있을 때만 커널모드로 모든 명령을 수행가능하다. CPU는 보안 관련 명령을 수행하기 전에는 항상 mode bit를 조사해 그 값이 0으로 세팅되어 있을 때만 수행한다.

###  메모리의 보안

- 사용자 프로그램이 다른 사용자 프로그램의 메모리 영역이나 운영체제 커널이 위치한 메모리 영역을 참조하려는 시도를 차단해야한다.
- 하나의 프로그램이 메모리의 한 영역에 연속적으로 위치하는 단순화된 메모리 관리기법을 사용하는 경우에 2개의 레지스터를 사용해서 프로그램이 접근하려는 메모리 부분이 합법적인지 체크함으로써 메모리를 보호할 수 있다. 운영체제는 2개의 레지스터 값을 직접 세팅할 수 있고 사용자 프로그램은 세팅할 수 없다.
- 하나의 프로그램이 메모리의 여러 영역에 나뉘어 위치하는 페이징(paging) 기법을 사용할 경우 추가적인 방법이 필요하다.
- 메모리 접근 연산이 있을 때마다 체크한다. 잘못된 메모리 영역을 참조하려는 시도는 예외를 발생시키고, 운영체제로 CPU의 제어권을 넘긴 후 해당 프로그램을 강제로 종료시킨다.
- 기준 레지스터
	- 기준 레지스터는 어떤 프로그램이 수행되는 동안 그 프로그램이 합법적으로 접근할 수 있는 메모리상의 가장 작은 주소를 보관하고 있다.
- 한계 레지스터
	- 한계 레지스터는 그 프로그램이 기준 레지스터값부터 접근할 수 있는 메모리의 범위를 보관하고 있다.

###  CPU의 보안

- CPU가 하나의 프로그램에 의해 독점되는 것을 막기 위해 운영체제는 timer라는 하드웨어를 사용한다.

###  시스템 콜을 이용한 입출력 수행

- 입출력 명령은 운영체제만 수행할 수 있는 명령이다.
- 사용자 프로그램은 직접 입출력을 수행하는 대신 운영체제에게 시스템 콜이라는 서비스 대행요청을 하여 입출력을 수행한다.
- 시스템 콜은 소프트웨어적인 인터럽트로서 사용자 프로그램이 시스템 콜을 할 경우 트랩이 발생해 CPU의 제어권이 운영체제로 넘어가게 된다.

##  프로그램의 구조와 실행

###  프로그램의 구조와 인터셉트

- 프로그램이 CPU에서 명령을 수행하려면 해당 명령을 담은 프로그램의 주소 영역이 메모리에 올라가 있어야 한다.

- 프로그램의 주소 영역
	- code
		- 우리가 작성한 프로그램 함수들의 코드가 CPU에서 수행할 수 있는 기계어 명령 형태로 변환되어 저장되는 부분이다.
	- data
		- 전역 변수 등 프로그램이 사용하는 데이터를 저장하는 부분이다.
	- stack
		- 함수가 호출될 때 호출된 함수의 수행을 마치고 복귀할 주소 및 데이터를 임시로 저장하는 데에 사용되는 공간이다.
		- CPU가 함수를 실행하다가 다른 함수를 호출하면 다른 함수의 코드로 수행 위치를 이동하여 실행하고 수행을 마치고 다시 돌아와야 하는 복귀 주소를 스택에 저장한다.
		- 인터럽트의 동작 원리도 함수 호출과 유사하다. 인터럽트 발생시 복귀주소는 각 프로그램의 주소 공간 중 스택에 저장한다.
		- 인터럽트 발생시 CPU를 빼앗긴 시점의 위치는 운영체제가 관리하는 프로세스 제어블록에 저장된다. 프로세스 제어 블록에는 인터럽트가 발생한 시점에서 그 프로그램의 어느 부분까지 수행했는지를 저장하며, 인터럽트 처리 후 프로세스 제어블록에 저장된 주소를 복원시켜 원래 수행하던 일을 재개하게 된다.

###  컴퓨터 시스템의 작동 개요

- 프로그램 카운터(Program Counter, PC)
	- CPU는 매 시점 메모리의 특정 주소에 존재하는 명령을 하나씩 읽어와 그대로 실행한다.
	- 이때 CPU가 수행해야할 메모리 주소를 담고 있는 레지스터를 프로그램 카운터라고 부른다.
	- 즉 CPU는 매번 프로그램 카운터가 가리키는 메모리 위치의 명령을 처리하게 된다. 일반적으로 조건문이나 반복문, 함수 호출등에 의한 주소 이동이 없는 이상 프로그램 카운터는 항상 바로 다음 명령을 가리키게 되어 코드의 순차적인 수행이 이루어진다.

- 컴퓨터 시스템 구조

- CPU: 명령 수행
	- 일반 명령
		- 메모리에서 자료를 읽어와 CPU에서 계산하고 결과를 메모리에 쓰는 일련의 명령
		- 모든 프로그램이 수행가능한 명령이다.
	- 특권 명령
		- 보안이 필요한 명령이다. 운영체제만 수행할 수 있도록 제한되어있다.
		- CPU 내의 모드 비트(mode bit)로 명령 실행가능성을 체크한다.
		- 사용자 프로그램이 특권 명령 실행이 필요한 경우 운영체제에게 특권 명령의 대행을 요청하는 시스템 콜(system call)을 실행한다.
		- CPU는 인트럽트 신호가 들어왔는지 매 명령을 수행한 직후 인터럽트 라인을 확인한다. 인터럽트 발생시 CPU는 해당 인터럽트를 처리하기 위한 루틴으로 넘어가서 커널내의 인터럽트 처리 코드를 수행한다.
- 메모리
	- 사용자 프로그램들과 운영체제가 같이 올라가 수행된다.
	- CPU는 프로그램 카운터가 가리키는 메모리의 위치의 프로그램을 수행한다.
- 외부 장치 입출력 연산
	- 입출력 장치별로 존재하는 작은 CPU와 메모리를 각각 입출력 컨트롤러와 로컬버퍼라고 부른다.

- 프로그램의 실행
	- 의미
		- 디스크에 존재하는 실행 파일이 메모리에 적재되어있고
		- 프로그램이 CPU를 할당받고 명령을 수행하고 있는 상태를 의미한다.
	- 실행 파일이 메모리에 적재 될 때 일반적으로 실행파일 전체가 올라가는게 아니라 실행하는 일부분만 메모리에 올라가고 나머지는 디스크의 스왑영역에 내려가 있다.
	- 프로세스의 주소 공간은 코드, 데이터, 스택 등으로 구성된다. 각각의 프로그램마다 실제 메모리 주소와 독립적으로 이러한 주소 공간을 별도로 가지며, 프로그램마다 독자적으로 존재하는 이와 같은 주소 공간을 우리는 가상 메모리 또는 논리적 메모리라고 부른다.
	- 운영체제도 하나의 프로그램이므로 운영체제 커널도 코드, 데이터, 스택 주소공간을 가지고 있다.
	- 커널의 데이터 영역에는 각종 자원을 관리하기 위한 자료구조가 저장된다. 현재 수행중인 프로그램인 프로세스(process)의 상태, CPU 사용 정보, 메모리 사용 정보 등을 유지하기 위한 자료구조인 PCB를 두고 있다.
	- 커널의 스택 영역은 함수호출시의 복귀 주소를 저장하기 위한 용도로 사용한다. 일반 사용자 프로그램의 스택과 달리 현재 수행중인 프로세스 마다 별도의 스택을 두어 관리한다. 모든 사용자 프로그램이 시스템 콜을 통해 커널의 함수에 접근한뒤에 다시 각자의 프로세스의 복귀주소로 돌아가야하기 때문이다.
	- 유의할 점은 프로그램 내의 함수호출 시 해당 프로그램의 스택에 복귀 주소를 저장하지만, 시스템 콜이나 인터럽트 발생으로 CPU의 수행 주체가 운영체제로 바뀌는 순간에는 직전에 수행되던 프로그램의 복귀정보를 스택이 아닌 PCB에 저장한다는 점이다.
	- 이때 커널 역시 함수구조로 이루어져 있으므로, 커널의 코드가 수행되는 도중에 이루어지는 함수호출은 커널스택을 사용하게 되는 것이다. 커널스택은 프로세스마다 별도로 두고 있어, 커널 내에서 이루어지는 함수호출은 직전에 CPU를 가지고 있던 프로세스의 커널 스택을 사용하게 된다.

- 사용자 프로그램이 사용하는 함수
	- 프로그램이 사용하는 함수의 종류
		- 사용자 정의 함수
		- 라이브러리 함수
		- 커널 함수
		- 시스템 콜 함수
		- 인터럽트 처리 함수

	- 사용자 정의 함수와 라이브러리 함수는 모두 그 프로그램의 코드 영역에 기계어 명령 형태로 존재한다. 따라서 프로그램이 실행 될 때 해당 프로세스의 주소 공간에 포함되며, 또한 함수호출 시에도 자신의 주소 공간에 있는 스택을 사용하게 된다.
	- 커널함수는 운영체제 커널의 주소 공간에서 코드가 정의된다.

- 인터럽트
	- CPU는 매번 프로그램 카운터가 가리키는 곳에 있는 명령을 수행하는 일 밖에 하지 않기 때문에 현재 수행 중인 프로세스로부터 CPU를 회수해 CPU가 다른 일을 수행하도록 하기 위해서는 인터럽트 매커니즘이 필요하다.
	- CPU는 매번 프로그램 카운터가 가리키고 있는 지점의 명령을 하나씩 수행하고 나서, 다음 명령을 수행하기 직전에 인터럽트 라인이 세팅되었는지 체크한다.
	- 체크 후 인터럽트가 발생했으면 CPU는 현재 수행하던 프로세스를 멈추고 운영체제의 인터럽트 처리루틴으로 이동해서 인터럽트 처리를 수행한다.
	- 인터럽트의 처리를 마치고 나면 인터럽트가 발생하기 직전의 프로세스에게 CPU의 제어권이 다시 넘어가게 된다.
	- 상대적으로 중요도가 낮은 인터럽트를 처리하는 도중에 중요도가 높은 인터럽트가 발생시 현재 처리 중이던 인터럽트 코드의 수행지점을 저장하고 우선순위가 높은 인터럽트를 처리하고 다시 이전에 수행하던 인터럽트 처리를 마저 수행한다.
	- 상대적으로 중요도가 낮은 인터럽트를 처리하는 도중에 중요도가 높은 인터럽트가 발생시 현재 처리 중이던 인터럽트 코드의 수행지점을 저장하고 우선순위가 높은 인터럽트를 처리하고 다시 이전에 수행하던 인터럽트 처리를 마저 수행한다.

  
- 시스템 콜
	- 커널이라는 운영체제의 주소 공간에 존재하는 함수를 호출하는 것을 시스템 콜이라고 한다.
	- 프로그램이 스스로 인터럽트 라인에 인터럽트를 세팅하는 명령을 통해 이루어진다.
	- 인터럽트 발생시 CPU의 제어권은 운영체제로 넘어가고 특권 명령을 실행하게 된다.
	- 예를 들어 입출력 명령 실행시 CPU는 입출력 명령을 내린 후 다른 프로그램으로 제어권을 이양해서 다른일을 처리하다가 입출력작업이 완료되면 디스크 컨트롤러가 CPU에게 인터럽트를 발생시킨다. CPU는 로컬버퍼로 읽어온 내용을 컴퓨터 내의 메모리로 복사한 후 최초에 입출력을 요청했던 프로세스에게 다시 CPU를 획득할 권한을 준다. 그러면 해당 프로세스는 CPU를 기다리는 큐에 삽입되고 순서를 기다려서 CPU의 제어권을 획득할 수 있다.

  

- 프로세스의 실행 상태
	- 프로세스는 사용자 모드와 커널모드를 오가면서 명령을 수행한다.
	- user mode running
		- 사용자 프로그램의 주소 공간에 정의된 코드를 실행할 때
	- kernel mode running
		- 커널의 시스템 콜 함수를 실행할 때



## 프로세스 관리

- 프로세스란?
	- 프로세스는 실행 중인 프로그램을 의미한다. job 이라는 용어와 혼용해서 사용
	- 프로세스를 이해하기 위해서는 프로세스 문맥(context)에 대한 이해가 필요하다. 
		- 여러 프로세스가 함께 수행되는 시분할 시스템 환경에서는 CPU의 제어권을 잠깐씩 점유하여 사용하기 때문에 다시 획득해서 명령의 수행을 재개하는 시점이 되면 이전의 CPU 보유 시점에 어느 부분까지 명령을 수행했는지 직전 수행 시점의 정확한 상태를 재현할 필요가 있다.
		- 프로세스의 문맥은 그 프로세스의 주소 공간을 비롯해 레지스터에 어떤 값을 가지고 있었는지와, 시스템 콜 등을 통해 커널에서 수행한 일의 상태, 그 프로세스에 관해 커널이 관리하고 있는 각종 정보 등을 포함하게 된다.
		- 프로세스 문맥을 크게 3가지로 분류
			- 하드웨어 문맥
				- CPU의 수행상태를 나타내는 것으로 프로그램 카운터값과 각종 레지스터에 저장하고 있는 값들을 의미한다.
			- 프로세스의 주소 공간
				- 프로세스는 코드, 데이터, 스택으로 구성되는 자기 자신만의 독자적인 주소 공간을 가지고 있다.
			- 커널상의 문맥
				- 운영체제는 프로세스를 관리하기 위한 자료 구조인 PCB와 커널 스택을 유지한다.

- 프로세스의 상태
	- 시작
		- 프로세스가 시작되어 그 프로세스를 위한 각종 자료구조는 생성되었지만 아직 메모리 획득을 승인받지 못한 상태
	- 실행(running)
		- 실행 상태는 프로세스가 CPU를 보유하고. 기계어 명령을 실행하고 있는 상태
		- 실행 시킬 프로세스를 변경하기 위해 원래 수행 중이던 프로세스의 문맥을 저장하고 새로운 프로세스의 문맥을 세팅하는 과정을 context switch 라고 한다.
	- 준비(ready)
		- 프로세스가 CPU만 보유하면 당장 명령을 실행할 수 있지만 CPU를 할당받지 못한 상태
		- 인터럽트가 발생하거나 실행 중이던 프로세스가 봉쇄상태로 바뀌는 경우 준비 상태에 있는 프로세스들 중에서 CPU를 할당받을 프로세스를 선택한 후 실제로 CPU의 제어권을 넘겨받는 과정을 CPU dispatch라고 한다.
	- 봉쇄(blocked, wait, sleep)
		- CPU를 할당받더라도 당장 명령을 실행할 수 없는 프로세스의 상태
	- 완료
		- 프로세스가 종료되었으나 운영체제가 그 프로세스와 관련된 자료구조를 완전히 정리하지 못한 상태
	- 중지
		- 외부적인 이유로 프로세스의 수행이 정지된 상태 (inactive)
		- 중지 상태에 있는 프로세스는 외부에서 재개시키지 않는 이상 다시 활성화될 수 없으므로 메모리 자원이 필요하지 않기 때문에 중지 상태 프로세스의 메모리는 통째로 디스크로 스왑 아웃된다.
		- 중지준비(suspended ready)
		- 중지봉쇄(suspended blocked)

- 프로세스의 제어블록(Process Control Block)
	- PCB는 운영체제가 시스템 내의 프로세스들을 관리하기 위해 프로세스마다 유지하는 정보들을 담는 커널 내의 자료구조
	- 구성
		- 운영체제가 관리상 사용하는 정보
			- 프로세스의 상태, 프로세스 번호, 스케줄링 정보, 우선순위
		- CPU 수행 관련 하드웨어 값
			- 프로그램 카운터, 레지스터
		- 메모리 관련
			- 코드, 데이터, 스택의 위치 정보
		- 파일 관련
			- 프로세스가 오픈한 파일 정보

- 문맥 교환(context switch)
	- 문맥 교환이란 하나의 사용자 프로세스로부터 다른 사용자 프로세스로 CPU의 제어권이 이양되는 과정을 뜻한다.
	- 문맥 교환 중에 이전 프로세스는 프로세스 문맥을 자신의 PCB에 저장하고, 새롭게 CPU를 할당받을 프로세스는 예전에 저장했던 자신의 문맥을 PCB로부터 실제 하드웨어로 복원시키는 과정을 거친다.
	- 하나의 사용자 프로그램이 인터럽트나 시스템 콜이 발생할 경우 CPU의 제어권이 잠시 운영체제로 넘어갔다가 돌아오는 것은 문맥 교환이라고 하지 않는다. 
	- 문맥 교환에 소요되는 시간은 시스템 입장에서 일종의 오버헤드라고 할 수 있다. 문맥교환 중에 일어나는 작업은 실제 시스템에게 유용한 작업이 아니기 때문이다. 타이머에 CPU 할당 시간을 아주 작게 세팅하면 문맥교환이 빈번하게 발생하면 이에 드는 오버헤드가 상당히 커진다. 또 그 반대로 CPU 할당 시간을 너무 길게 설정하면 시분할 시스템의 의미가 퇴색하므로 적절한 CPU 할당시간을 정하는 것이 중요하다.

- process ready queue
	- 운영체제는 준비 상태에 있는 프로세스들을 줄 세우기 위해 큐를 두고 큐의 제일 앞에 줄 서 있는 프로세스에 제일 먼저 CPU를 할당한다.
	- 운영체제는 커널의 주소 영역 중 데이터 영역에 다양한 queue를 두어 프로세스의 상태를 관리한다.
	- 큐에 프로세스를 줄 세우는 방법은 CPU 스케줄링 방법에 따라 달라진다.
	- 큐는 각 프로세스의 PCB를 연결 리스트 형태로 관리하며 포인터를 사용해 순서를 정한다.
	- device queue
		- 운영체제는 특정 자원을 기다리는 프로세스들을 줄 세우기 위해 자원별로 장치 큐를 둔다.
		- Disk I/O queue, keyboard I/O queue...
	- job queue
		- 시스템 내의 모든 프로세스를 관리하기 위한 큐
		- 프로세스의 상태와 무관하게 현재 시스템 내에 있는 모든 프로세스가 작업 큐에 속하게 된다.

- 스케줄러(scheduler)
	- 스케줄러란 어떤 프로세스에게 자원을 할당할지를 결정하는 운영체제 커널의 코드를 지칭한다.
	- 장기 스케줄러(long term, job)
		- 어떤 프로세스를 준비 큐에 진입시킬지 결정하는 역할
		- 준비 큐는 CPU만 얻으면 당장 실행될 수 있는 프로세스의 집합이고, CPU에서 실행되기 위해서는 프로세스가 메모리를 보유해야 하므로 장기 스케줄러는 프로세스에게 메모리를 할당하는 문제에도 관여한다.
		- 수십 초 내지 수 분 단위로 가끔 호출되므로 단기 스케줄러에 비해 상대적으로 수행 속도가 느리다.
		- 과거에 자원이 매우 빈약하던 시절에 사용되었으며 현재 장기 스케줄러를 두지 않는게 대부분이다. 과거에는 적은 양의 메모리를 많은 프로세스들에게 할당하면 시스템 효율이 매우 떨어졌기 때문에 메모리에 동시에 올라가 있는 프로세스의 수를 조절하는 역할을 담당했다. 현재는 프로세스가 시작 상태가 되면 장기 스케줄러 없이 곧 바로 그 프로세스에 메모리를 할당해 준비 큐에 넣는다.

	- 중기 스케줄러(medium term)
		- 현재는 장기 스케줄러 대신 중기 스케줄러를 두는 경우가 많다.
		- 너무 많은 프로세스에게 메모리를 할당해 시스템의 성능이 저하되는 경우 이를 해결하기 위해 메모리에 적재된 프로세스의 수를 동적으로 조절하는 역할을 한다.
		- 프로세스당 보유 메모리양이 지나치게 적어진 경우 이를 완화시키기 위해 일부 프로세스를 메모리에서 디스크로 스왑 아웃시키는 역할을 수행한다.
		- 스왑아웃 시키는 대상의 0 순위는 봉쇄 상태에 있는 프로세스들이다. 그래도 메모리 공간이 부족한 경우 보통 타이머 인터럽트가 발생해 준비 큐로 이동하는 프로세스를 추가적으로 스왑 아웃 시켜서 당장 실행되는 프로세스가 사용할 메모리 공간을 확보한다.

	- 단기 스케줄러(short term, CPU scheduler)
		- 준비 상태의 프로세스 중에서 어떤 프로세스를 다음 번에 실행 상태로 만들 것인지 결정한다.
		- 타이머 인터럽트가 발생하면 단기 스케줄러가 호출된다.
		- 밀리초 정도의 시간 단위로 매우 빈번하게 호출되므로 빠른 수행 속도가 요구된다.

- 프로세스의 생성
	- 시스템이 부팅된 후 최초의 프로세스는 운영체제가 직접 생성하지만 그 다음부터는 이미 존재하는 프로세스가 다른 프로세스를 복제 생성하게 된다.
		- 자식 프로세스가 종료될 경우 부모 프로세스가 그에 대한 처리를 수행한다.
		- 부모 프로세스가 종료된다면 연관된 자식 프로세스를 모두 종료시킨 후에야 종료될 수 있다. 
	- 프로세스 수행 모델
		- 부모 프로세스와 자식 프로세스가 공존하며 수행되는 모델
		- 자식이 종료될 때까지 부모가 기다리는 모델
			- 자식 프로세스가 종료될 때 까지 부모 프로세스는 봉쇄 상태에 머무른다.
	- 부모 프로세스가 자식 프로세스를 생성하면 자식 프로세스는 부모 프로세스와는 별도의 주소 공간을 가지게 되는데, 처음 주소 공간을 생성할 때에는 부모 프로세스의 주소 공간의 내용(문맥 포함)을 그대로 복사해서 생성한다. (fork) 따라서 자식 프로세스는 부모 프로세스의 처음부터 수행을 시작하는 게 아니라 부모 프로세스가 현재 수행한 시점(프로그램 카운터 지점)부터 수행하게 된다.
	- 이렇게 복사한 자식 프로세스를 생성한 후 부모와는 다른 독자적인 프로그램을 수행시킬 수 있게 하기 위해 유닉스에서는 프로세스의 주소 공간에 새로운 프로그램을 덮어 씌우는 exec() 시스템 콜을 지원한다. 프로세스의 주소 공간을 완전히 새로운 프로그램으로 덮어 씌운 후 새로운 프로그램의 첫 부분부터 다시 실행을 시작하도록 한다.
	- wait() 시스템 콜은 자식 프로세스가 종료되기를 기다리며 부모 프로세스가 봉쇄 상태에 머무르도록 할 때 사용되며 자식 프로세스가 종료되야만 부모 프로세스를 준비 상태로 변경시키기 때문에 부모 프로세스와 자식 프로세스 간의 동기화를 가능하게 한다.

- 프로세스 간의 협력 
	- 원칙적으로 프로세스가 다른 프로세스의 독립적인 주소 공간을 참조하는 것은 허용되지 않기 때문에 다른 프로세스의 수행에 영향을 미칠 수 없다.
	- 그렇다면 독립적인 프로세스들의 협력은 어떻게 이루어 질까?
	- 운영체제는 IPC(Inter-Process Communication) 프로세스간 협력 매커니즘을 제공한다.
	- IPC는 하나의 컴퓨터 안에서 실행 중인 서로 다른 프로세스 간에 발생하는 통신을 말한다.
		- 의사소통 기능과 동기화가 보장되어야한다.
		- 메시지 전달 방식
			- 프로세스 간 공유 데이터를 일체 사용하지 않고 메시지를 주고 받으면서 통신하는 방식
			- 메시지 전달은 커널이 대신한다. 커널은 send 와 receive 연산을 제공하고 프로세스는 전달할 메시지를 운영체제에게 시스템 콜 방식으로 요청해 전달할 수 있다.
			- 직접 통신
				- 메시지의 전송 대상이 다른 프로세스 이므로 통신하려는 프로세스의 이름을 명시적으로 표시한다.
			- 간접 통신
				- 메시지를 메일 박스 또는 포트로부터 전달 받는다. 
		- 공유 메모리 방식
			- 프로세스들이 주소 공간의 일부를 공유한다.
			- 각 프로세스는 독자적인 주소 공간을 가지고 있지만, 주소 공간이 물리적 메모리에 매핑될 때 공유 메모리 주소 영역에 대해서는 동일한 물리적 메모리 주소로 매핑한다. 
			- 데이터 일관성 문제가 발생할 수 있으며 커널이 책임지지 않기 때문에 각 프로세스끼리 동기화 문제를 책임져야한다. 


## CPU 스케줄링

- CPU 버스트가 균일하지 않은 다양한 프로그램이 공존하므로 효율적인 CPU 스케줄링 기법이 필요하다.
	- 사용자 프로그램이 수행되는 과정은 CPU 작업과 I/O 작업의 반복으로 구성된다.
	- 각 프로그램마다 CPU 버스트와 I/O 버스트가 차지하는 비율이 균일하지는 않다.
	- 대부분의 프로세스가 짧은 CPU 버스트를 가지며 극히 일부분만 긴 CPU 버스트를 가진다. 
	- I/O 바운드 프로세스의 CPU 할당 우선 순위를 높여주어서 전체적인 효율을 높이는게 중요하다. 
	- CPU burst
		- 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 단계
		- Add, Load, Store 명령 등
	- I/O burst
		- I/O 요청이 발생해 커널에 의해 입출력 작업을 진행하는 비교적 느린 단계
		- 입출력 명령
	- I/O bound process
		- I/O 버스트가 빈번해 CPU 버스트가 매우 짧게 나타나는 프로세스
	- CPU bound process
		- I/O 를 거의 하지 않아 CPU 버스트가 매우 길게 나타나는 프로세스

- CPU 스케줄러
	- CPU 스케줄러는 준비 상태에 있는 프로세스들 중 어떠한 프로세스에게 CPU를 할당할지 결정하는 운영체제의 코드다. 
	- 프로세스가 명령을 수행 중 타이머 인터럽트가 발생하면 CPU 스케줄러가 호출되고 CPU 스케줄러는 준비 큐에서 CPU를 기다리는 프로세스 중 하나를 선택해 CPU를 할당한다.
	- 스케줄링 방식
		- 선점형
			- 프로세스가 CPU를 계속 사용하기를 원하더라도 강제로 빼앗을 수 있는 스케줄링 방법
			- 장점
				- 실행 중인 프로세스가 I/O 등의 이벤트 발생 등으로 인해 중단될 경우에 강제로 빼앗아 다른 프로세스에게 CPU를 할당할 수 있기때문에 CPU 자원을 효율적으로 활용할 수 있다.
			- 단점
				-  실행 중인 프로세스가 중간에 강제로 중지되어야 하므로, 이에 대한 오버헤드가 발생할 수 있다.
				- 실행 중인 프로세스가 다른 프로세스에 의해 계속 중지되면, 해당 프로세스의 실행 시간이 길어지며, 이는 일부 프로세스의 실행이 늦어질 가능성을 높일 수 있다.
			- 실행상태에 있던 프로세스가 타이머 인터럽트 발생에 의해 준비상태로 바뀌는 경우
			- I/O 요청으로 봉쇄 상태에 있던 프로세스의 I/O 작업이 완료되어 인터럽트가 발생하고 준비 상태로 바뀌고 완료된 프로세스가 인터럽트 당한 프로세스보다 우선순위가 높은 경우

		- 비선점형
			- CPU 비선점형 스케줄러란, 현재 CPU를 점유하고 있는 프로세스가 I/O 등의 이벤트 발생 등으로 실행 중지될 경우, 이 프로세스가 다시 실행 가능한 상태가 되기 전까지 다른 프로세스가 CPU를 점유하지 않고 대기하는 스케줄링 방식을 의미한다. 
			- 즉, CPU가 점유되고 있는 프로세스가 실행 중지되어도 다른 프로세스가 그 자리를 대기하는 것이 아니라, 해당 프로세스가 다시 실행 가능한 상태가 되기를 기다리는 것이다.
			- 장점
				- 실행 중인 프로세스가 실행을 잠시 멈추더라도 CPU 자원을 계속 활용할 수 있다.
				- 만약 CPU가 실행 중인 프로세스가 I/O 등의 이벤트 발생으로 인해 잠시 멈추는 경우, 다른 프로세스가 그 동안 CPU 자원을 활용하여 실행되므로, 전체적인 시스템 성능을 높일 수 있습니다.
			- 단점
				- 실행 중인 프로세스가 종료되기를 기다리는 경우에는 다른 프로세스가 CPU를 사용할 수 없다.
				- 실행 중인 프로세스가 짧은 시간 동안 실행되는 경우에는 효과적이지만, 실행 시간이 긴 프로세스의 경우 다른 프로세스가 오랜 시간 동안 CPU를 사용하지 못할 수 있다.
			- 실행 상태에 있던 프로세스가 I/O 요청에 의해 봉쇄 상태로 바뀌는 경우
			- CPU에서 실행 상태에 있는 프로세스가 종료되는 경우

- 디스패처(dispatcher)
	- CPU를 새롭게 할당받은 선택된 프로세스가 작업을 수행할 수 있도록 환경설정을 하는 운영체제의 코드를 디스패처라고 부른다. 
	- 디스패처는 현재 수행 중이던 프로세스의 문맥을 그 프로세스의 PCB에 저장하고 새롭게 선택된 프로세스의 문맥을 PCB로부터 복원한 후 그 프로세스에게 CPU를 넘기는 과정을 수행한다.
	- 디스패처가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간을 디스패치 지연시간이라고 하며, 디스패치 지연시간의 대부분은 문맥교환 오버헤드에 해당한다.
	- 새로운 프로세스의 문맥을 복원시킨 후에는 시스템의 상태를 사용자모드로 전환해 사용자 프로그램에게 CPU의 제어권을 넘긴다.
	- 사용자 프로그램은 복원된 문맥 중 프로그램 카운터로부터 현재 수행할 주소를 찾아서 명령을 실행한다.

- 스케줄링의 성능 평가
	- 시스템 관점 지표
		- CPU 이용률
			- 전체 시간 중 CPU가 일을 한 시간의 비율. 휴먼 상태의 시간의 비율을 최대한 줄여야 좋다.
		- 처리량
			- 주어진 시간 동안 준비 큐에서 기다리고 있는 프로세스 중 몇개를 끝마쳤는지를 나타낸다.
			- 여러 프로세스가 CPU를 기다리고 있는 상황에서 주어진 시간에 더 많은 프로세스들이 CPU 작업을 완료하기 위해서는 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 할당하는 것이 유리하다.
	- 사용자 관점 지표
		- 소요시간
			- 프로세스가 CPU를 요청한 시점부터 자신이 원하는 만큼 CPU를 다 쓰고 CPU 버스트가 끝날때까지 걸린시간
			- 준비큐에서 기다린 시간과 실제로 CPU를 사용한 시간의 합을 의미한다.
		- 대기시간
			- CPU 버스트 기간 중 프로세스가 준비 큐에서 CPU를 얻기 위해 기다란 시간의 합을 뜻한다.
		- 응답시간
			- 프로세스가 준비 큐에 들어온 후 첫번째 CPU를 획득하기까지 기다린 시간을 뜻한다.
			- 타이머 인터럽트가 빈번하게 발생할수록 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 짧아지므로 처음 CPU를 얻기까지 걸리는 시간은 줄어들게 되어 응답시간이 향상된다.

- 스케줄링 알고리즘
	- 선입선출(First-Come First-Served, FCFS) 스케줄링
		- 프로세스가 준비큐에 도착한 시간 순서대로 CPU를 할당하는 방식
		- 먼저 요청한 프로세스에게 CPU를 먼저 할당하고 자발적으로 CPU를 반납할 때까지 빼앗지 않는다.
		- CPU 버스트가 긴 프로세스가 먼저 요청할 경우, CPU를 잠깐만 사용하면 준비 큐를 떠나 I/O 작업을 수행할 수 있는 다수의 프로세스들이 기다리는 비효율이 발생할 수 있다.
		- 이러한 비효율적인 현상은 콘보이(conboy) 현상이라고 부른다.
	
	- 최단작업(Shortest-Job First, SJF) 우선 스케줄링
		- CPU 버스트가 가장 짧은 프로세스에게 제일 먼저 CPU를 할당하는 방식
		- 평균 대기시간이 가장 짧게 하는 최적 알고리즘
		- 비선점형 방식으로 구현
			- CPU를 획득하면 그 프로세스가 자진 반납하기 전까지 CPU를 빼앗지 않는 방식
		- 선점형 방식으로 구현
			- 준비큐에서 CPU 버스트가 가장 짧은 프로세스에게 CPU를 할당했다 하더라도, CPU 버스트가 더 짧은 프로세스가 도착할 경우 CPU를 빼앗아 더 짧은 프로세스에게 부여하는 방식
			- 실행 중인 프로세스의 남은 CPU 버스트 시간보다 더 짧은 CPU 버스트 시간을 가지는 프로세스가 도착할 경우 CPU를 빼앗는다.(Shortest Remaining Time First, SRTF)
			- 보통 CPU작업을 필요로하는 프로세스가 동시에 준비 큐에 도착하지 않는다. 그래서 프로세스들이 준비 큐에 도착하는 시간이 불규칙한 환경에서는 선점형 방식이 프로세스들의 평균 대기시간을 최소화하는 최적의 알고리즘이 된다.
			- 프로세스의 CPU 버스트 시간은 과거의 CPU 버스트 시간을 통한 예측치로 비교한다.
		- CPU 버스트가 짧은 프로세스가 계속 도착할 경우 긴 CPU 버스트 시간을 갖는 프로세스는 영원히 CPU를 할당받을 수 없을 수도 있게된다. 이러한 현상을 기아(starvation)현상이라고 부른다.
	
	- 우선순위(priority) 스케줄링
		- 준비 큐에서 기다리는 프로세스들 중 우선순위가 가장 높은 프로세스에게 제일 먼저 CPU를 할당하는 방식
		- 최단작업 우선 스케줄링처럼 기아 현상이 발생할 수 있다.
		- 기아 현상을 해결하기 위해 노화(aging) 기법을 사용할 수 있다.
			- 기다리는 시간이 길어질수록 우선순위를 조금씩 높여서 너무 오래기다리지 않게 한다.

	- 라운드 로빈(Round Robin) 스케줄링
		- 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 특정 시간으로 제한되며, 제한 시간이 경과하면 타이머 인터럽트로 CPU를 회수하고 준비큐에 대기하는 다른 프로세스에게 CPU를 할당하는 방식
		- 각 프로세스마다 한번에 CPU를 연속적으로 사용할 수 있는 최대시간을 할당 시간이라고 부른다.
		- 할당시간이 너무 길면 라운드 로빈 스케줄링은 FCFS와 같은 결과를 나타낸다.
		- 할당시간이 너무 짧으면 프로세스가 빈번하게 교체되어 문맥교환의 오버헤드가 커진다.
		- 일반적으로 할당시간은 수십 밀리초 정도의 규모로 설정한다. 이는 사람이 느리지 않다고 체감할 정도의 시간안에 한번씩은 CPU를 할당받을 수 있게 한 것이다.
		- 라운드 로빈 스케줄링은 일반적으로 SJF 방식보다 평균 대기시간은 길지만 응답시간은 더 짧다.

	- 멀티 레벨 큐
		- 준비 큐를 여러개로 분할해 관리하는 스케줄링 기법
		- 성격이 다른 프로세스들을 별도로 관리하고, 프로세스의 성격에 맞는 스케줄링을 적용하기 위해 준비 큐를 별도로 두어서 관리한다.
		- 빠른 응답을 필요로 하는 대화형 작업을 담기위한 전위 큐
			- 응답시간을 짧게 하기위해 라운드 로빈 스케줄링을 사용한다.
		- 계산 위주의 작업을 담기위한 후위 큐
			- 응답시간은 큰 의미가 없으므로 문맥 교환 오버헤드를 줄이기 휘해 FCFS 스케줄링을 사용
		- 여러 개의 준비 큐 자체에 적용할 스케줄링 기법
			- 고정 우선순위 방식
				- 큐에 고정적인 우선 순위를 부여해 우선순위가 높은 큐를 먼저 서비스하고 우선순위가 낮은 큐는 우선순위가 높은 큐가 비어있을 때에만 서비스한다.
			- 타임 슬라이스 방식
				- 큐에 대한 기아 현상을 해소할 수 있는 방식으로 각 큐에 CPU 시간을 적절한 비율로 할당한다. 

	- 멀티 레벨 피드백 큐
		- CPU를 기다리는 프로세스를 여러 큐에 줄 세운다는 측면에서 멀티레벨 큐와 동일하나, 프로세스가 하나의 큐에서 다른 큐로 이동 가능하다는 점이 다르다.
		- 우선순위가 낮은 큐에서 오래기다린 프로세스를 우선순위가 높은 큐로 이동시켜 기아현상을 해결할수도 있다.

	- 다중처리기 스케줄링
		- CPU가 여러개인 시스템을 다중처리기 시스템이라고 부른다.
		- 프로세스를 준비 큐에 한 줄로 세워서 각 CPU가 알아서 다음 프로세스를 꺼내어 가도록할 수 있다.
			- 은행창구에서 번호표를 뽑은 고객을 호출하는 방식과 유사하다.
		- 또는 각 CPU 별로 여러줄로 준비 큐를 관리할 수도 있다. 이때 각 CPU별 부하가 적절히 분산되도록 하는 부하 균형 매커니즘을 필요로 한다. (load balancing)

	- 실시간 스케줄링
		- 실시간 시스템에서는 각 작업마다 주어진 데드라인이 있어서 정해진 데드라인 안에 반드시 작업을 처리해야한다.
		- 데드라인이 얼마 남지 않은 요청을 먼저 처리하는 EDF(Earlist Deadline First) 스케줄링을 사용한다.
		- hard real-time system: 미사일 발사, 원자로 제어같이 반드시 정해진 시간을 지켜야한다.
		- soft real-time system: 멀티미디어 스트리밍 시스템. 데드라인을 못지켜도 위험한 상황이 발생하지는 않음

- 스케줄링 알고리즘의 평가 방식
	- 큐잉 모델
		- 확률분포를 통해 프로세스들의 도착률과 CPU의 처리율을 입력값으로 주어서 수학적 계산을 통해 각종 성능지표인 CPU 처리량, 프로세스의 평균 대기시간 등을 구한다.
	- 시뮬레이션
		- 가상의 CPU 스케줄링 프로그램을 작성한 후 프로그램의 CPU 요청을 입력값으로 넣어 결과를 확인하는 방법
		- 입력값은 가상으로 사용할 수 있고 실제 시스템에서 추출한 입력값인 트레이스(trace)를 사용할 수도 있다. 
		- 트레이스는 몇 초에 어떤 프로세스가 도착하고, 각각 CPU 버스트 시간을 얼마로 하는지에 대한 정보를 시간 순서대로 적어놓은 파일을 의미한다.
	- 구현 및 실측
		- 실제로 커널의 스케줄링을 수행하는 코드를 직접 수정하여 실행시간을 측정한 후 비교하고 알고리즘의 성능을 평가한다.


## 메모리 관리
- 메모리는 주소를 통해 접근하는 저장 장치이다.
- byte 단위로 메모리 주소가 부여된다.
- 효율적인 운영을 위해 연속된 일련의 영역을 행정구역 처럼 4kb 단위로 묶어서 페이지라고 부르며 사용
- 페이지 내에서 바이트별 위치 구분을 위해서는 12비트가 필요하다.
- 메모리를 어떠한 행정구역으로 나누어 관리할 것인가?
- 프로그램이 물리적 메모리에 어떻게 올라가서 주소를 할당받게 되는가?

### 주소 바인딩
- 주소바인딩이란 프로세스의 논리적 주소를 물리적 메모리 주소로 연결시켜 주는 작업이다.
	- 프로그램이 실행을 위해 메모리에 적재되면 그 프로세스를 위한 독자적인 주소 공간이 생성된다.
	- CPU는 프로세스마다 독립적으로 갖는 논리적 주소에 근거해 명령을 실행한다.
	- 물리적 주소는 물리적 메모리에 실제로 올라가는 위치를 말한다. 보통 물리적 메모리의 낮은 주소영역에는 운영체제가 올라가고, 높은 주소 영역에는 사용자 프로세스들이 올라간다.
- 주소 바인딩 방식은 프로그램이 적재되는 물리적 메모리의 주소가 결정되는 시기에 따라 분류할 수 있다.
	- 컴파일 타임 바인딩
		- 물리적 메모리 주소가 프로그램을 컴파일 할 때 결정되는 주소 바인딩 방식
		- 컴파일 하는 시점에 해당 프로그램이 물리적 메모리의 몇 번지에 위치할 것인지 결정된다.
		- 절대 코드(absolute code)를 생성하는 바인딩 방식이라고도 말한다.
		- 프로그램이 올라가있는 물리적 메모리의 위치를 변경하기 위해서는 다시 컴파일해야하기 때문에 잘 사용하지 않는 방법이다.
	- 로드 타임 바인딩
		- 프로그램이 실행이 시작될 때 물리적 메모리 주소가 결정되는 주소 바인딩 방식
		- 로더(loader)의 책임하에 물리적 메모리 주소가 부여되며 프로그램이 종료될 때까지 물리적 메모리상의 위치가 고정된다.
		- 로더란 사용자 프로그램을 메모리에 적재시키는 프로그램을 말한다.
		- 컴파일러가 재배치 가능 코드(relocatable code)를 생성한 경우에 가능한 주소 바인딩 방식이다.
	- 실행시간 바인딩(execution time binding, run time binding)
		- 프로그램이 실행 중인 경우에도 그 프로그램이 위치한 물리적 메모리상의 주소가 변경될 수 있는 바인딩 방식
		- CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지, 주소 매핑 테이블(address mapping table)을 이용해 바인딩을 점검해야한다.
		- 기준(base) 레지스터와 한계(limit) 레지스터를 포함하여 MMU(memory management unit)의 하드웨어적인 지원이 필요하다.
		-  MMU는 CPU가 특정 프로세스의 논리적 주소를 참조하려고 할 때 그 주소 값에 기준 레지스터의 값을 더해 물리적 주소값을 얻어낸다. 기준 레지스터에는 특정 프로세스의 물리적 메모리 시작 주소가 저장되어있다. 
		- MMU 기법에서는 프로그램의 주소 공간이 물리적 메모리의 한 장소에 연속적으로 적재되는 것으로 가정하기 때문에 그 프로그램이 적재되는 물리적 메모리상의 시작 주소만 알면 주소 변환이 쉽게 가능하다.
		- MMU 기법에서 사용자 프로그램과 CPU는 논리적 주소만을 다룰 뿐 실제 물리적 주소는 알지 못하며 알아야할 필요도 없다.
		- MMU 기법에서는 문맥교환으로 CPU에서 수행 중인 프로세스가 바뀔 때마다 재배치 레지스터의 값을 그 프로세스에 해당되는 값으로 재설정함으로써 각 프로세스에 맞는 주소에 접근할 수 있다.
		- 메모리 참조시 한계 레지스터로 프로세스가 자신의 주소 공간을 넘어서는 메모리 참조를 우선 체크하여 메모리 보안을 유지할 수 있다. 한계레지스터를 넘어서는 다른 프로세스에 접근하려는 시도이므로 트랩을 발생시켜 해당 프로세스를 강제로 종료시킨다.

### 메모리 관리

- 동적 로딩(dynamic loading)
	- 여러 프로그램이 동시에 메모리에 올라가서 수행되는 다중 프로그래밍 환경에서 메모리 사용의 효율성을 높이기 위해 사용하는 기법이다.
	- 프로세스의 주소 공간 전체를 메모리에 다 올려놓지 않고 프로세스 내에서 실행에 필요한 부분이 실제로 불릴 때마다 그 부분만을 메모리에 적재하는 방식을 사용한다.
	- 동적로딩은 운영체제의 특별한 지원 없이 프로그램 자체에서 구현이 가능하며 운영체제가 라이브러리를 통해 지원할 수도 있다.

- 동적 연결(dynamic linking)
	- linking이란 프로그래머가 작성한 소스 코드를 컴파일하여 생성된 목적(object) 파일과 이미 컴파일된 라이브러리 파일들을 묶어 하나의 실행파일을 생성하는 과정을 말한다.
	- 동적 연결은 컴파일을 통해 생성된 목적 파일과 라이브러리 파일 사이의 연결을 프로그램의 실행 시점까지 지연시키는 기법이다. 
		- 반대로 정적(static) 연결에서는 프로그래머가 작성한 코드와 라이브러리 코드가 모두 합쳐져서 실행파일이 생성된다. 상대적으로 실행파일의 크기가 크며 동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재해야하므로 물리적 메모리가 낭비되는 단점이 있다.
	- 동적 연결에서는 라이브러리가 실행 시점에 연결된다. 즉 실행 파일에 라이브러리 코드가 포함되지 않으며, 프로그램이 실행되면서 라이브러리 함수를 호출할 때가 되어서야 라이브러리에 대한 연결이 이루어진다.
	- 동적연결을 가능하게 하기위해 실행파일의 라이브러리 호출 부분에 해당 라이브러리 위치를 찾기 위한 스텁(stub)이라는 작은 코드를 둔다. 스텁을 통해 해당 라이브러리가 이미 메모리에 존재하면 직접 참조하며, 존재하지 않으면 디스크에서 동적 라이브러리 파일을 찾아 메모리로 적재한 후 수행한다.
	- 동적연결에서는 공통으로 사용하는 라이브러리를 한번만 메모리에 적재하므로 메모리를 효율적으로 사용할 수 있다. 
	- 동적 연결 기법은 운영체제의 지원을 필요로한다. 

- 중첩(overlays)
	- 프로세스의 주소 공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법
	- 초창기의 컴퓨터 시스템에서 물리적 메모리의 크기 제약으로 인해 하나의 프로세스조차도 메모리에 한꺼번에 올릴 수 없을 때 프로세스의 주소 공간을 분할해서 당장 필요한 일부분을 메모리에 올려 실행하고 해당부분에 대한 실행이 끝난 후에 나머지 부분을 올려 실행하는 기법을 뜻한다.
	- 동적로딩에서는 메모리의 이용률을 향상시키기 위해 프로세스의 주소 공간 중 당장 실행에 필요한 부분을 그때그때 메모리에 동적으로 올려서 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 용도였다면, 중첩은 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 어쩔 수 없는 선택이었다.

- 스와핑(swapping)
	- 메모리에 올라온 프로세스의 주소 공간 전체를 디스크의 스왑영역(swap area)에 일시적으로 내려놓는 것을 의미한다. 내리는 작업은 swap out, 메모리로 다시 올리는 작업을 swap in 이라고 부른다.
	- 스왑 영역은 백킹스토어(backing store)라고도 부르며 디스크내에 파일 시스템과는 별도로 존재하는 일정 영역을 말한다.
	- 중기 스케줄러에 의해 스왑 아웃 대상으로 선정된 프로세스에 대해서 메모리 주소 공간 내용을 통째로 스왑 아웃시킨다. 
	- 스와핑은 메모리에 존재하는 프로세스의 수를 조절하는 역할을 한다. 스와핑을 통해 프로세스당 메모리의 양이 지나치게 적어지는 것을 방지한다.
	- 스와핑에서는 보통 디스크 내의 스왑 영역에 프로세스의 주소 공간이 순차적으로 저장되기 때문에, 디스크의 탐색 시간이나 회전지연시간보다는 디스크 섹터에서 실제 데이터를 읽고 쓰는 전송 시간이 소요시간의 대부분을 차지한다.

### 물리적 메모리의 할당방식
- 물리적 메모리는 운영체제 상주 영역과 사용자 프로세스 영역으로 나뉘어 사용된다.
	- 운영체제 상주 영역은 인터럽트 벡터와 함께 물리적 메모리의 낮은 주소 영역을 사용하며, 운영체제 커널이 이곳에 위치한다.
	- 사용자 프로세스 영역은 물리적 메모리의 높은 주소영역을 사용하며 여러 사용자 프로세스들이 이곳에 적재되어 실행된다.
- 사용자 프로세스 영역의 관리 방법은 프로세스를 메모리에 올리는 방식에 따라 분류할 수 있다.
	- 연속할당(contiguous allocation)
		- 각각의 프로세스를 물리적 메모리의 연속적인 공간에 올리는 방식이다.
		- 물리적 메모리를 다수의 분할로 나누어 하나의 분할에 하나의 프로세스가 적재되도록한다.
		- 고정분할
			- 물리적 메모리를 고정된 크기의 분할(partition)로 미리 나누어두는 방식
			- 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되있으며 수행 가능한  프로그램의 최대 크기도 제한된다.
			- 외부조각과 내부조각이 발생할 수 있다.(external, internal fragmentation)
		- 가변분할
			- 분할을 미리 나누어놓지 않은 채 프로그램이 실행되고 종료되는 순서에 따라 분할을 관리하는 방식이다.
			- 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변한다.
			- 동적 메모리 할당 문제
				- 물리적 메모리 내 가용 공간 중 어떤 위치에 프로세스를 올릴 것인가? 실험 결과 최초적합 방식이나 최적적합방식이 보다 효과적이다.
				- 최초적합 방법
					- 가용 공간을 차례대로 살펴보면서 프로그램보다 작지 않은 가용공간이 최초로 발견되면 할당
				- 최적적합 방법
					- 프로그램의 크기 이상인 가장 작은 가용 공간을 찾아 할당
					- 모든 가용 공간 리스트를 탐색하는 오버헤드 발생
					- 다수의 매우 작은 가용공간들이 생성될 수 있는 단점 존재
				- 최악적합 방법
					- 가용 공간 중에서 가장 크기가 큰 곳에 할당
					- 모든 가용 공간 리스트를 탐색하는 오버헤드 발생
					- 상대적으로 더 큰 프로그램을 담을 수 있는 가용공간을 빨리 소진할 수 있는 단점 존재
			- 컴팩션(compation)
				- 가변분할 방식에서 발생하는 외부조각 문제를 해결하기 위한 방법
				- 물리적 메모리 중에서 프로세스에 의해 사용중인 메모리 영역과 가용공간을 각각 한쪽으로 모아서 하나의 큰 가용 공간을 만드는 방법
				- 수행 중인 프로세스의 물리적 메모리 위치를 옮겨야 하므로 프로그램의 실행 도중에 프로세스의 주소가 동적으로 바뀔수 있는 실행시간 바인딩 방식이 지원되는 환경에서만 수행가능
	- 불연속할당(noncontiguous allocation)
		- 하나의 프로세스를 물리적 메모리의 여러 영역에 분산해 적재하는 방식
		- 페이징(paging) 기법
			- 각 프로세스의 주소 공간을 동일한 크기의 페이지로 잘라서 메모리에 페이지 단위로 적재함.
			- 물리적 메모리를 페이지와 동일한 크기의 프레임으로 미리 나누어둔다.
			- 논리적 주소를 물리적 주소로 변환할 때 페이지 단위로 이루어져야 하므로 특정 프로세스의 몇번째 페이지가 물리적 메모리의 몇번째 프레임에 들어있다는 페이지별 주소 변환을 위한 페이지 테이블을 모든 프로세스가 가지고 있어야 한다.
			- 주소 변환 기법
				- 논리적 주소를 페이지 번호와 페이지 오프셋으로 나누어 사용
				- 페이지 번호는 페이지 테이블 접근 시 인덱스로 사용되고 해당 페이지의 물리적 메모리상의 시작 위치가 저장되어있다.
				- 페이지 오프셋은 하나의 페이지 내에서의 변위를 알려준다.
			- 페이지 테이블
				- 페이지 테이블은 물리적 메모리에 위치하며 CPU에서 실행중인 프로세스의 페이지 테이블에 접근하기 위해 운영체제는 페이지 테이블 기준 레지스터와 페이지 테이블 길이 레지스터를 사용한다.
				- 페이지 테이블 접근 오버헤드를 줄이기 위해서 TLB라고 불리는 고속의 주소 변환용 하드웨어 캐시가 사용되기도 한다.
			- 계층적 페이징
				- 페이지 테이블을 위한 메모리 공간의 사용은 낭비가 심하다.
				- 주소변환을 위해 외부 페이지 테이블과 내부 페이지 테이블의 두 단계에 걸친 페이지 테이블을 사용
				- TLB를 함께 사용시 메모리 접근 시간에 대한 오버헤드를 줄일 수 있다.
			- 역페이지 테이블
				- 물리적 메모리의 페이지 프레임 하나당 페이지 테이블에 하나씩의 항목을 두는 방식
				- 물리적 주소에 대해 페이지 테이블을 시스템 전체에 대해 1개만 만든다. 
				- 페이지 테이블은 프로세스번호(pid)와 그 프로세스 내의 논리적 페이지 번호를 담고 있다.
			- 공유 페이지
				- 공유페이지는 공유 코드를 담고 있는 페이지를 의미한다.
					- 공유 코드는 메모리 공간의 효율적인 사용을 위해 여러 프로세스에 의해 공통으로 사용될 수 있도록 작성된 코드로 재진입 가능코드 또는 순수코드라고도 불리며 읽기 전용의 특성을 가지고 있다.
				- 공유페이지는 그 페이지를 공유하는 모든 프로세스의 주소 공간에서 동일한 페이지 번호를 가져야한다.
			- 메모리 보호
				- 페이지 테이블의 각 항목에는 메모리 보호를 위한 보호 비트와 유효-무효 비트를 두고 있다.
				- 보호 비트에는 각 페이지에 대해 읽기-쓰기/읽기전용 등의 접근 권한을 설정하는데 사용
				- 유효비트가 유효로 세팅되어있으면 해당 메모리 프레임에 페이지가 존재하므로 접근 허용된다.
				- 유효비트가 무효로 세팅되어있으면 프로세스가 그 주소 부분을 사용하지 않거나, 해당 페이지가 물리적 메모리에 올라와 있지 않고 백킹스토어에 존재하므로 해당 메모리 프레임에 유효한 접근 권한이 없다는 의미를 가진다. 
		- 세그먼테이션(segmentation) 기법
			- 프로그램의 주소 공간을 코드, 데이터, 스택 등 의미있는 단위인 세그먼트로 나누어 적재함.
			- 크기가 균일하지 않은 세그먼트들을 메모리에 적재하는 부가적인 관리 오버헤드가 생긴다.
			- 세그먼트 단위로 프로세스 간의 공유나 프로세스 내의 접근 권한 보호가 이루어질 수 있다.
		- 페이지드 세그먼테이션(paged segmentation) 기법
			- 세그먼트 하나를 다수의 페이지로 구성하는 기법으로 두 방법의 장점만을 취하는 방법
			- 의미단위의 세그먼트가 동일한 크기 페이지들의 집합으로 구성된다.
			- 외부의 세그먼트 테이블과 내부의 페이지 테이블을 사용하여 주소변환을 수행한다.

## 가상 메모리(virtual memory)
- 운영체제는 어떤 방식으로 프로세스에게 메모리를 할당하는가? 
- 시분할 시스템 환경에서는 한정된 메모리 공간을여러 프로그램이 조금씩 나누어 사용하고 보통 몇몇 프로그램들에게 집중적으로 메모리를 할당하고 회수하는 방식을 채택한다.
- 프로세스의 빠른 수행을 위해 프로그램마다 최소한 확보해야하는 메모리의 크기가 존재하기 때문이다.
- 기본적으로 당장 필요하지 않은 부분은 디스크의 스왑 영역에 내려놓았다가 사용하기 때문에 프로그램 입장에서는 물리적 메모리 크기에 대한 제약이 없다고 봐도 된다. 운영체제는 더 나아가 프로그램이 물리적 메모리를 고려할 필요없이 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원한다. 
- 프로그램은 0번지 부터 시작하는 자기 자신만의 메모리 주소 공간인 가상 메모리를 가정할 수 있다. 필요시 가상메모리의 일부만이 스왑영역에서 메모리에 swap in 하여 사용하게 된다. 
- 프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 가상메모리 기법은 요구 페이징 방식과 요구 세그먼테이션 방식으로 구현될수 있다.

### 요구 페이징(demand paging)
- 프로그램 실행시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라 당장 사용될 페이지만을 올리는 방식을 말한다.
- 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재한다.
- 당장 실행할 페이지만을 메모리에 적재하기 때문에 메모리 사용량이 감소하고, 프로세스 전체를 메모리에 올리는 데 소요되는 입출력 오버헤드도 줄어든다.
- 프로그램을 구성하는 페이지 중 사용하는 일부만을 메모리에 적재하므로 물리적 메모리의 용량보다 큰 프로그램도 실행할 수 있게 된다.
- 특정 프로세스를 구성하는 페이지 중에서 메모리에 존재하는지 여부를 구별하기 위하여 유효-무효 비트를 두어 각 페이지가 메모리에 존재하는지 표시하게 된다.
- 요구페이징의 부재 처리
	- CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우 페이지 부재(page fault)가 일어났다고 말한다.
	- CPU가 무효 페이지에 접근하면 주소 변환을 담당하는 MMU가 페이지 부재 트랩(trap)을 발생시킨다.
- 요구 페이징의 성능
	- 성능에 가장 큰 영향을 미치는 요소는 페이지 부재의 발생 빈도이다.
	- 페이지 부재가 일어나면 요청된 페이지를 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생한다.
- 페이지 교체
	- 페이지 부재가 발생해서 요청된 페이지를 디스크에서 메모리로 읽어와야할 때 물리적 메모리에 빈 프레임이 존재하지 않을 수 있다.
	- 이 경우에는 메모리에 올라와 있는 페이지 중 하나를 swap out 하여 빈 공간을 확보하는 페이지 교체작업이 필요하다. 
	- 어떠한 프레임에 있는 페이지를 swap out 할지 결정하는 알고리즘인 교체 알고리즘의 목표는 페이지 부재율을 최소화하는 것이다.
	- 어떻게 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택하여 swap out 시킬 수 있을까?
		- 최적 페이지 교체 알고리즘
			- 가장 먼 미래에 참조될 페이지를 swap out
			- 발레디의 최적 알고리즘
			- 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제하에 알고리즘을 운영하기 때문에 현실에 적용할수는 없는 오프라인 알고리즘으로 다른 알고리즘의 성능에 대한 상한선을 제공한다.
		- 선입선출 알고리즘
			- 페이지 교체시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 swap out
			- 교체 대상 페이지가 계속해서 많은 참조가 이루어지면서 메모리 공간이 늘어나도 성능이 나빠지는 FIFO 이상현상(FIFO anomaly)이 발생할 수 있다.
		- LRU 알고리즘(Least Recently Used)
			- 페이지 교체시 마지막 참조 시점이 가장 오래된 페이지를 swap out
			- 메모리 페이지의 참조 성향 중 시간지역성을 반영
			- 시간지역성이란 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질
		- LFU 알고리즘(Least Frequently Used)
			- 페이지의 참조 횟수가 가장 적었던 페이지를 swap out
			- LRU 알고리즘 보다 오랜 시간동안 참조기록을 반영할 수 있다는 장점이 있지만 LFU 알고리즘은 시간에 따른 페이지 참조의 변화를 반영하지 못한다. 
			- Incache-LFU
				- 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식
				- 페이지가 메모리에서 쫓겨났다가 다시 들어온 경우 참조횟수는 초기화됨
			- Perfect-LFU
				- 메모리에 올라와있는지의 여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트하는 방식
				- 오버헤드가 상대적으로 크다.
		- 클럭 알고리즘
			- 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체한다.
			- 클럭 알고리즘은 하드웨어적인 지원을 통해 참조시각 및 참조 횟수를 비교하고 유지하여 오버헤드를 줄인 방식이다.
			- 각 프레임마다 참조 비트가 하나씩 존재하며 그 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅된다.
			- 교체할 페이지를 선정하기 위해 페이지 프레임들의 참조 비트를 순차적으로 조사하여 참조 비트가 1인페이지는 0으로 바꾼후 지나가고 참조비트가 0인 페이지는 교체한다. 모든 페이지 프레임을 다 조사한 경우 첫번째 페이지 프레임부터 조사작업을 반복한다.
			- 시곗바늘이 한바퀴 돌아오는 동안에 다시 참조되지 않을 경우 페이지는 교체된다. 
			- 적어도 시곗바늘이 한바퀴를 도는데 소요되는 시간만큼 페이지를 메모리에 유지시켜둠으로써 페이지 부재율을 줄이도록 설계되었기 때문에 2차기회 알고리즘이라고도 부른다.

	- 페이지 프레임의 할당
		- 프로세스 여러 개가 동시에 수행되는 상황에서 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인가?
			- 프로세스를 정상적으로 수행하기 위해서는 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야한다.
				- CPU에서 명령을 실행할 때에는 일반적으로 여러 페이지를 동시에 참조하게 된다. 명령을 실행할 때 프로세스의 주소 공간 중 코드, 데이터, 스택 등 각기 다른 영역을 참조하기 때문이다.
				- 반복문을 구성하는 페이지도 한꺼번에 메모리에 올려야 페이지 부재가 발생하지 않는다.
		- 할당 방식
			- 균등 할당
				- 모든 프로세스에게 페이지 프레임을 균일하게 할당한다. 
			- 비례 할당
				- 프로세스의 크기에 비례해 페이지 프레임을 할당한다.
			- 우선순위 할당 
				- 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당한다.

	- 전역 교체와 지역 교체
		- 전역 교체
			- 모든 페이지 프레임이 교체 대상이 될 수 있다. 
			- 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법이다. 
			- 교체되는 페이지가 어떤 프로세스에 속한 것인지 고려하지 않기 때문에 교체시 다른 프로세스에 할당된 프레임을 빼앗아올 수 있다. 결과적으로 프로세스별 프레임 할당량을 조절할 수 있게 된다.
			- LRU, LFU 클럭 등의 알고리즘을 물리적 메모리 내에 존재하는 전체 페이지 프레임들을 대상으로 적용하는 경우를 말한다. 
			- 워킹셋 알고리즘
			- PFF 알고리즘
		- 지역 교체
			- 현재 수행중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있다.
			- 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 한다.
			- 프로세스별로 페이지 프레임을 할당하고, 교체할 페이지도 그 프로세스에게 할당된 프레임 내에서 선정하게 된다.
			- LRU, LFU 등의 알고리즘을 프로세스별로 독자적으로 운영하는 경우를 말한다.

	- 스레싱
		- 스레싱 현상이란 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 않아서 페이지 부재율이 크게 상승해 CPU 이용률이 급격히 떨어지는 것을 말한다.
		- 메모리에 동시에 올라가 있는 프로세스의 수를 다중 프로그래밍의 정도 (Multi-Programming Degree, MPD)라고 부른다.
		- 운영체제는 CPU 이용률이 낮을 경우 추가로 프로세스를 메모리에 올려서 MPD를 높인다. 그러나 어느 정도 MPD 이상일 경우 페이지 부재가 발생하는 빈도가 높아지면서 CPU 이용률이 다시 낮아지고 운영체제가 착각하여 다시 MPD를 높이는 악순환이 발생한다.
		- 그러므로 스레싱을 발생하지 않도록 하면서 CPU 이용률을 최대한 높일 수 있도록 MPD를 조절하는 것이 중요하다.
		- 워킹셋 알고리즘
			- 프로세스는 일정시간동안 특정 주소 영역을 집중적으로 참조하는 경향이 있다.
			- 이렇게 집중적으로 참조되는 페이지들의 집합을 지역성 집합(locality set)이라고 한다.
			- 워킹셋 알고리즘은 이러한 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘이다.
			- 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만 프로세스에게 메모리를 할당한다.
			- 그렇지 않을 경우 프로세스에게 할당된 페이지 프레임을 모두 반납후 swap out시킨다.
		- 페이지 부재 알고리즘
			- 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절한다.
			- 어떤 프로세스의 페이지 부재율이 시스템에서 미리 정해놓은 상한 값을 넘게되면 이 프로세스에 할당된 프레임 수가 부족하다고 판단하여 이 프로세스에게 프레임을 추가로 더 할당한다.
			- 이때 추가로 할당할 빈 프레임이 없다면 일부 프로세스를 swap out 시켜서 메모리에 올라가있는 프로세스의 수를 조절한다.
			- 반대로 페이지 부재율이 하한값 이하로 떨어지면 이 프로세스에게 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄이고 추가로 swap out 되어있던 프로세스에게 프레임을 할당함으로써 MPD를 높인다.


## 디스크 관리

### 디스크의 구조
- 논리 블록(logical block)
	- 디스크 외부에서는 디스크를 일정한 크기의 저장공간들로 이루어진 1차원 배열처럼 취급한다.
	- 일정한 크기의 저장공간을 논리블록이라고하며, 디스크에 데이터가 저장될 때에는 논리블록 단위로 저장되고, 디스크 외부로 입출력이 일어날 때에도 논리블록 단위로 전송된다.
	- 논리 블록에 저장된 데이터에 접근 시 배열에 접근하는 것처럼 해당 블록의 인덱스 번호를 디스크에 전달해야한다. 그러면 디스크 컨트롤러는 해당 논리블록이 저장된 물리적 위치를 찾아 요청된 데이터에 대한 입출력 작업을 수행하게 된다.
- 섹터(sector)
	- 각 논리블록이 저장되는 디스크내의 물리적인 위치
	- 논리블록과 섹터 하나와 1대1로 매핑되어 저장된다.
- 마그네틱 원판
	- 각각의 원판은 트랙으로 구성되고 각 트랙은 섹터로 나뉘며, 섹터에 최소한의 단위 정보가 저장된다.
- 실린더
	- 여러개의 원판에서 상대적 위치가 동일한 트랙들의 집합
	- 섹터 0은 최외곽 실린더의 첫번째 트랙에 있는 첫번째 섹터이다.
	- 디스크에 데이터를 읽고 쓰기 위해서는 암(arm)이 해당 섹터가 위치한 실린더로 이동한 후 원판이 회전하여 디스크헤드가 저장된 섹터 위치에 도달해야한다.

### 디스크 스케줄링
- 디스크에 대한 접근시간 = 탐색시간 + 회전지연시간 + 전송시간
	- 탐색시간은 디스크 헤드를 해당 실린더 위치로 이동시키는데 걸리는 시간
	- 회전지연시간은 디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간
	- 전송시간은 해당 섹터가 헤드 위치에 도달한 후 데이터를 실제로 섹터에 읽고 쓰는데 소요되는 시간
- 어떻게 디스크의 입출력 효율을 높이기 위하여 접근 시간을 최소화할 것인가?
	- 운영체제 입장에서 회전지연시간과 전송시간은 통제하기 힘든 부분
	- 운영체제는 탐색시간을 줄이기 위해서 헤드의 움직임을 최소화하는 스케줄링 작업을 한다.
	- 디스크 스케줄링이란 효율적인 디스크 입출력을 위해 여러 섹터들에 대한 입출력 요청이 들어왔을 때 이들을 어떠한 순서로 처리할 것인지 결정하는 메커니즘을 말한다.
	- 디스크 스케줄링의 가장 중요한 목표는 디스크 헤드의 이동거리를 줄이는 것이다.
	- 디스크 스케줄링 기법은 엘리베이터의 스케줄링 문제와 유사하다.
- 종류
	- FCFS 스케줄링
		- 디스크에 먼저 들어온 요청을 먼저 처리한다.
		- 입출력 요청이 디스크의 한쪽 끝과 반대쪽 끝에 번갈아 도착한다면 헤드는 디스크를 계속 왕복하며 일을 처리해야하므로 탐색 시간이 매우 비효율적으로 늘어날 수 있다.
	- SSTF 스케줄링
		- 헤드의 현재 위치로 부터 가장 가까운 위치에 있는 요청을 제일 먼저 처리한다.
		- 헤드의 이동거리를 줄일 수 있지만 자칫 기아 현상을 발생시킬 수 있다.
		- 현재의 헤드 위치로부터 가까운 곳에서 지속적인 요청이 들어올 경우 헤드 위치에서 멀리 떨어진 곳의 요청은 무한히 기다려야할 수 있다.
	- SCAN 알고리즘
		- 헤드가 디스크 원판의 안쪽 끝과 바깥쪽 끝을 오가며 그 경로에 존재하는 모든 요청을 처리한다. 
		- 디스크의 어떠한 위치에 요청이 들어오는가와 상관없이 헤드는 정해진 방향으로 이동하면서 길목에 있는 요청들을 처리하며 지나가는 것이다.
		- 버스가 일정 경로에 따라 움직이며 정류장에서 기다리고 있는 사람들을 태우는 것과 유사한 방식이다.
		- 엘리베이터 스케줄링 알고리즘이라고도 부른다. 한 방향으로 이동하면서 진행 경로에 같은 방향으로 가는 승객이 있으면 모두 태운다. 
		- 효율성과 형평성을 모두 만족하는 알고리즘이지만 탐색시간의 편차가 존재하기에 C-SCAN 알고리즘이 제안되었다.
	- C-SCAN 알고리즘(circular)
		- 헤드가 한쪽 끝에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리하지만 SCAN과 달리 헤드가 다른 쪽 긑에 도달해 방향을 바꾼 후에는 요청을 처리하지 않고 곧바로 출발점으로 다시 이동만 한다.
		- SCAN 보다 좀 더 균일한 탐색시간을 제공한다.
	- LOOK 과 C-LOOK 알고리즘
		- SCAN 알고리즘과 달리 헤드가 한쪽 방향으로 이동하다가 그 방향에 더이상 대기중인 요청이 없으면 헤드의 이동방향을 즉시 반대로 바꾸는 스케줄링 방식이다.
		- C-LOOK 알고리즘 C-SCAN 알고리즘처럼 한 쪽 방향으로 요청을 처리한다. 

### 다중 디스크 환경에서의 스케줄링
- 다중 디스크 사용시 같은 데이터가 저장되어있는 여러 개의 디스크 중 어느 디스크에서 요청을 처리할지 결정하는 스케줄링 문제가 발생한다. 
- 스케줄링 목표
	- 각 디스크간의 부하 균형을 이루도록 스케줄링하여 요청이 각 디스크로 골고루 분배되도록 한다.
	- 탐색 시간을 줄이기 위해 헤드의 현재 위치가 요청한 데이터와 가장 가까운 디스크를 선택한다.
	- 전력소모를 줄이기 위해 일부 디스크에 요청을 집중시킬 수도 있다.

### 디스크의 저전력관리
- 디스크의 상태
	- 활성 상태
		- 활동 상태
			- 현재 헤드가 데이터를 읽거나 쓰고 있는 상태
		- 공회전 상태
			- 디스크가 회전 중이지만 데이터를 읽거나 쓰지는 않는 상태
	- 비활성 상태 
		- 준비 상태
			- 디스크가 회전하지는 않지만 인터페이스가 활성화된 상태
		- 휴먼 상태
			- 디스크가 회전하지도 않고 인터페이스도 비활성화된 상태
- 비활성화 기법
	- 요청이 없을 경우 디스크를 비활성 상태로 정지시킨다.
	- 하지만 비활성 상태에서 데이터를 읽고 쓰려면 활성 상태일 때보다 몇 초의 부가적인 시간과 2배정도의 부가적인 전력 소모가 뒤따른다.
	- 후속 요청까지의 시간 간격이 일정 시간 이상일 경우에만 디스크의 회전을 정지시키는게 효과적이다.
	- 디스크를 비활성화하는 시점을 결정하는 방법으로 시간 기반 기법과 예측 기반 기법, 확률 기반 기법이 있다.
- 회전속도 조절 기법
	- 전력소모를 줄이기위해 디스크의 회전 속도를 가변적으로 조절하는 기법
	- 운영체제는 시스템 자원과 부하를 포괄적으로 볼 수 있기 때문에 하드웨어 혼자서 전력관리를 하는 것에 비해 더 많은 전력 절감 효과를 얻을 수 있다.
- 디스크의 데이터 배치 기법
	- 디스크의 53% 이상이 빈 공간인 상태로 남아 있다는 점에 착안해 디스크 내에 데이터의 복제본을 많이 만들어서 헤드 위치에서 가까운 복제본에 접근하도록 함으로써 빠른 응답시간과 전력소모량 절감을 얻는 실험적인 FS2 파일 시스템을 개발되기도 하였다.
- 버퍼 캐싱 및 사전인출 기법
	- 미래에 요청될 데이터를 미리 알거나 어느정도 예측할 수 있다면 디스크가 활성 상태일 때 헤드위치로부터 가까운 데이터를 사전인출함으로써 향후 디스크의 비활성화 가능성을 높여 전력소모를 줄일 수도 있다.
- 쓰기전략을 통한 저전력 디스크 기법
	- 대상 디스크가 비활성 상태일 때에는 디스크 쓰기를 하지 않고 기다렸다가 디스크가 활성상태로 돌아왔을 때 쓰는 방식으로 전력 소모를 줄이는 방안이 연구되었다.